# Importing necessary libraries
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, explained_variance_score
import matplotlib.pyplot as plt

from google.colab import files

# Upload the data file
uploaded = files.upload()

# Load input data
input_data = pd.read_excel('raw_data_scaled.xlsx')
target_data = pd.read_excel('fuel_consumption_scaled.xlsx')

# Aggregate minute-level input data to daily-level
input_data_daily = input_data.resample('D', on='date').mean()

# Merge input data with target data based on date
merged_data = pd.merge(input_data_daily, target_data, on='date')

# Assuming you have additional columns for each engine's data in input_data
# You can include them in the features X
X = merged_data[['wind_speed', 'ship_speed', 'me1_rpm', 'me2_rpm', 'me3_rpm', 'me4_rpm', 'me1_power', 'me2_power', 'me3_power', 'me4_power']]
y = merged_data['fuel_consumption']

# Split the data into training+validation and test sets (80-20 split)
X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Initialize the Random Forest Regressor
model = RandomForestRegressor(random_state=42)

# Define hyperparameters for tuning
param_grid = {
    'n_estimators': [500, 1000, 1300],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt', 'log2']
}

# Use GridSearchCV for hyperparameter tuning and cross-validation
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1, verbose=2)

# Perform the grid search on the training+validation set
grid_search.fit(X_train_val, y_train_val)

# Retrieve the best model from grid search
best_model = grid_search.best_estimator_

# Print the best parameters found by GridSearchCV
print("Best hyperparameters:", grid_search.best_params_)

# Perform 5-fold cross-validation on training+validation set and calculate metrics
cv_scores_r2 = cross_val_score(best_model, X_train_val, y_train_val, cv=5, scoring='r2')
cv_scores_mse = cross_val_score(best_model, X_train_val, y_train_val, cv=5, scoring='neg_mean_squared_error')
cv_scores_mae = cross_val_score(best_model, X_train_val, y_train_val, cv=5, scoring='neg_mean_absolute_error')
cv_scores_ev = cross_val_score(best_model, X_train_val, y_train_val, cv=5, scoring='explained_variance')

# Print the metrics for each fold
print("Cross-validation results per fold:")
for i in range(5):
    print(f"Fold {i+1}:")
    print(f"  R-squared: {cv_scores_r2[i]}")
    print(f"  Mean Squared Error: {-cv_scores_mse[i]}")  # Negate MSE and MAE to show positive values
    print(f"  Mean Absolute Error: {-cv_scores_mae[i]}")
    print(f"  Explained Variance: {cv_scores_ev[i]}")

# Print the average cross-validated metrics
print("\nAverage cross-validated metrics:")
print(f"Cross-validated R-squared: {np.mean(cv_scores_r2)}")
print(f"Cross-validated Mean Squared Error: {-np.mean(cv_scores_mse)}")
print(f"Cross-validated Mean Absolute Error: {-np.mean(cv_scores_mae)}")
print(f"Cross-validated Explained Variance Score: {np.mean(cv_scores_ev)}")

# Train the model
best_model.fit(X_train_val, y_train_val)

# Predict on the test set
y_pred = best_model.predict(X_test)

# Calculate metrics on the test set
test_r2 = r2_score(y_test, y_pred)
test_mse = mean_squared_error(y_test, y_pred)
test_mae = mean_absolute_error(y_test, y_pred)
test_ev = explained_variance_score(y_test, y_pred)

# Print the metrics on the test set
print("R-squared on test set:", test_r2)
print("Mean Squared Error on test set:", test_mse)
print("Mean Absolute Error on test set:", test_mae)
print("Explained Variance Score on test set:", test_ev)

# Plotting actual vs. predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, color='blue', label='Actual vs. Predicted')
plt.plot([y.min(), y.max()], [y.min(), y.max()], '--k', color='red', label='Perfect prediction')
plt.title('Actual vs. Predicted Fuel Consumption (Random Forest Regressor)')
plt.xlabel('Actual Fuel Consumption')
plt.ylabel('Predicted Fuel Consumption')
plt.legend()
plt.show()
