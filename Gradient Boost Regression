# Importing necessary libraries
!pip install scikit-learn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import (
    r2_score, mean_squared_error, mean_absolute_error,
    explained_variance_score, mean_squared_log_error, median_absolute_error
)
from sklearn.preprocessing import StandardScaler
from google.colab import files

# Upload the data file
uploaded = files.upload()

# Load input data
input_data = pd.read_excel('mean_duration_miles (1).xlsx')
target_data = pd.read_excel('fuel_consumption (1).xlsx')

# Merge input data with target data based on date
merged_data = pd.merge(input_data, target_data, on='date')

# Features and target
X = merged_data[['ship_speed', 'me1_rpm', 'me2_rpm', 'me3_rpm', 'me4_rpm', 'me1_hr', 'me2_hr', 'me3_hr', 'me4_hr', 'miles']]
y = merged_data['fuel_consumption']

# Discretize target variable for Stratified K-Fold
y_binned = pd.cut(y, bins=5, labels=False)

# Scale features and target
scaler_X = StandardScaler()
scaler_y = StandardScaler()
X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()

# Set up 5-fold cross-validation using StratifiedKFold
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Model parameters
gbr_params = {'n_estimators': 45, 'random_state': 42}
epochs = 50

# Store metrics and learning curves
metrics = ['rmse', 'mae', 'r2', 'ev', 'msle', 'medianae']
learning_curves = {m: [] for m in metrics}
learning_curves.update({m + '_train': [] for m in metrics})
avg_metrics = {m: [] for m in metrics}  # Store final metrics for each fold

# Perform stratified cross-validation
fold = 1
for train_index, test_index in skf.split(X_scaled, y_binned):
    print(f"\nFold {fold}")
    X_train, X_val = X_scaled[train_index], X_scaled[test_index]
    y_train, y_val = y_scaled[train_index], y_scaled[test_index]

    model = GradientBoostingRegressor(**gbr_params)

    fold_learning = {m: [] for m in learning_curves}

    for epoch in range(epochs):
        model.n_estimators = epoch + 1
        model.fit(X_train, y_train)

        # Predictions (scaled and descaled)
        y_train_pred, y_val_pred = model.predict(X_train), model.predict(X_val)
        y_train_pred_unscaled = scaler_y.inverse_transform(y_train_pred.reshape(-1, 1))
        y_val_pred_unscaled = scaler_y.inverse_transform(y_val_pred.reshape(-1, 1))
        y_train_unscaled = scaler_y.inverse_transform(y_train.reshape(-1, 1))
        y_val_unscaled = scaler_y.inverse_transform(y_val.reshape(-1, 1))

        # Clip negative predictions for MSLE
        y_train_pred_unscaled = np.clip(y_train_pred_unscaled, a_min=0, a_max=None)
        y_val_pred_unscaled = np.clip(y_val_pred_unscaled, a_min=0, a_max=None)

        # Compute metrics
        for metric, func in zip(metrics, [mean_squared_error, mean_absolute_error, r2_score,
                                           explained_variance_score, mean_squared_log_error, median_absolute_error]):
            fold_learning[metric + '_train'].append(np.sqrt(func(y_train_unscaled, y_train_pred_unscaled))
                                                    if metric in ['rmse', 'msle'] else func(y_train_unscaled, y_train_pred_unscaled))
            fold_learning[metric].append(np.sqrt(func(y_val_unscaled, y_val_pred_unscaled))
                                         if metric in ['rmse', 'msle'] else func(y_val_unscaled, y_val_pred_unscaled))

    for key in learning_curves:
        learning_curves[key].append(fold_learning[key])

    # Store final metrics for this fold
    for metric in metrics:
        avg_metrics[metric].append(fold_learning[metric][-1])

    fold += 1

# Compute average learning curves
avg_learning_curves = {key: np.mean(np.vstack(learning_curves[key]), axis=0) for key in learning_curves}

# Plot learning curves
plt.figure(figsize=(12, 8))
for metric in metrics:
    plt.plot(range(1, epochs + 1), avg_learning_curves[metric], label=f'Test {metric.upper()}')
    plt.plot(range(1, epochs + 1), avg_learning_curves[f'{metric}_train'], linestyle='dashed', label=f'Train {metric.upper()}')
    plt.xlabel("Epochs")
    plt.ylabel(metric.upper())
    plt.title(f"Learning Curve for {metric.upper()}")
    plt.legend()
    plt.grid(True)
    plt.show()

# Print average metrics across folds
print("\nUnscaled Average Metrics Across All Folds:")
for metric in metrics:
    print(f"Average {metric.upper()}: {np.mean(avg_metrics[metric])}")
