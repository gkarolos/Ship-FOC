# Importing necessary libraries
!pip install scikit-learn
from IPython import get_ipython
from IPython.display import display
import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LinearRegression
from sklearn.metrics import (
    r2_score, mean_squared_error, mean_absolute_error,
    explained_variance_score, mean_squared_log_error, median_absolute_error
)
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from google.colab import files

# Upload the data file
uploaded = files.upload()

# Load input data
input_data = pd.read_excel('mean_duration_miles.xlsx')
target_data = pd.read_excel('fuel_consumption.xlsx')

# Merge input data with target data based on date
merged_data = pd.merge(input_data, target_data, on='date')

# Features and target
X = merged_data[['ship_speed', 'me1_rpm', 'me2_rpm', 'me3_rpm', 'me4_rpm', 'me1_hr', 'me2_hr', 'me3_hr', 'me4_hr', 'miles']]
y = merged_data['fuel_consumption']

# Discretize the target variable for Stratified K-Fold (since it's regression, not classification)
y_binned = pd.cut(y, bins=5, labels=False)

# Scale both features and target
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()

# Implement gradient descent to identify optimal learning rate (modification for MSLE and MedianAE)
def gradient_descent(X, y, X_val, y_val, scaler_y, alpha=0.01, epochs=1000):
    m, n = X.shape
    theta = np.zeros(n)  # Initialize parameters
    learning_curve = {'rmse': [], 'rmse_train': [], 'mae': [], 'mae_train': [], 'r2': [], 'r2_train': [], 'ev': [], 'ev_train': [], 'msle': [], 'msle_train': [], 'medianae': [], 'medianae_train': []}

    for epoch in range(epochs):
        predictions = np.dot(X, theta)
        errors = predictions - y

        # Compute training metrics (unscale RMSE, MAE, MSLE, and MedianAE)
        unscaled_y_train = scaler_y.inverse_transform(y.reshape(-1, 1))
        unscaled_predictions_train = scaler_y.inverse_transform(predictions.reshape(-1, 1))

        # Clip any negative values to zero to guarantee positive values for MSLE
        unscaled_predictions_train = np.clip(unscaled_predictions_train, a_min=0, a_max=None)

        learning_curve['rmse_train'].append(np.sqrt(mean_squared_error(unscaled_y_train, unscaled_predictions_train)))
        learning_curve['mae_train'].append(mean_absolute_error(unscaled_y_train, unscaled_predictions_train))
        learning_curve['r2_train'].append(r2_score(y, predictions))
        learning_curve['ev_train'].append(explained_variance_score(y, predictions))

        # MSLE and MedianAE for training
        learning_curve['msle_train'].append(np.sqrt(mean_squared_log_error(unscaled_y_train, unscaled_predictions_train)))
        learning_curve['medianae_train'].append(median_absolute_error(unscaled_y_train, unscaled_predictions_train))

        # Compute gradient and update theta
        gradient = (1 / m) * np.dot(X.T, errors)
        theta -= alpha * gradient

        # Validation predictions
        val_predictions = np.dot(X_val, theta)
        unscaled_y_val = scaler_y.inverse_transform(y_val.reshape(-1, 1))
        unscaled_predictions_val = scaler_y.inverse_transform(val_predictions.reshape(-1, 1))

        # Clip any negative values to zero to guarantee positive values for MSLE
        unscaled_predictions_val = np.clip(unscaled_predictions_val, a_min=0, a_max=None)

        learning_curve['rmse'].append(np.sqrt(mean_squared_error(unscaled_y_val, unscaled_predictions_val)))
        learning_curve['mae'].append(mean_absolute_error(unscaled_y_val, unscaled_predictions_val))
        learning_curve['r2'].append(r2_score(y_val, val_predictions))
        learning_curve['ev'].append(explained_variance_score(y_val, val_predictions))

        # MSLE and MedianAE for validation
        learning_curve['msle'].append(np.sqrt(mean_squared_log_error(unscaled_y_val, unscaled_predictions_val)))
        learning_curve['medianae'].append(median_absolute_error(unscaled_y_val, unscaled_predictions_val))

    return theta, learning_curve

# Set up 5-fold cross-validation using StratifiedKFold
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

alpha = 0.01  # Learning rate
epochs = 1000

# Store metrics
rmse_scores = []
mae_scores = []
r2_scores = []
ev_scores = []
msle_scores = []
medianae_scores = []
learning_curves = {'rmse': [], 'rmse_train': [], 'mae': [], 'mae_train': [], 'r2': [], 'r2_train': [], 'ev': [], 'ev_train': [], 'msle': [], 'msle_train': [], 'medianae': [], 'medianae_train': []}

fold = 1
for train_index, test_index in skf.split(X_scaled, y_binned):
    print(f"\nFold {fold}")
    X_train_fold, X_val_fold = X_scaled[train_index], X_scaled[test_index]
    y_train_fold, y_val_fold = y_scaled[train_index], y_scaled[test_index]

    # Train model
    optimal_theta, learning_curve = gradient_descent(X_train_fold, y_train_fold, X_val_fold, y_val_fold, scaler_y, alpha, epochs)

    for key in learning_curves:
        learning_curves[key].append(learning_curve[key])

    # Get predictions
    y_val_pred_fold = np.dot(X_val_fold, optimal_theta)

    # Clip any negative values to zero to guarantee positive values for MSLE
    y_val_pred_fold_unclipped = scaler_y.inverse_transform(y_val_pred_fold.reshape(-1, 1))
    y_val_pred_fold_clipped = np.clip(y_val_pred_fold_unclipped, a_min=0, a_max=None)

    # Compute unscaled metrics
    fold_rmse = np.sqrt(mean_squared_error(scaler_y.inverse_transform(y_val_fold.reshape(-1, 1)),
                                           y_val_pred_fold_clipped))
    fold_mae = mean_absolute_error(scaler_y.inverse_transform(y_val_fold.reshape(-1, 1)),
                                   y_val_pred_fold_clipped)
    fold_r2 = r2_score(y_val_fold, y_val_pred_fold)
    fold_ev = explained_variance_score(y_val_fold, y_val_pred_fold)
    fold_msle = np.sqrt(mean_squared_log_error(scaler_y.inverse_transform(y_val_fold.reshape(-1, 1)),
                                               y_val_pred_fold_clipped))
    fold_medianae = median_absolute_error(scaler_y.inverse_transform(y_val_fold.reshape(-1, 1)),
                                          y_val_pred_fold_clipped)

    rmse_scores.append(fold_rmse)
    mae_scores.append(fold_mae)
    r2_scores.append(fold_r2)
    ev_scores.append(fold_ev)
    msle_scores.append(fold_msle)
    medianae_scores.append(fold_medianae)

    fold += 1

# Compute the average learning curves
avg_learning_curves = {key: np.mean(np.vstack(learning_curves[key]), axis=0) for key in learning_curves}

# Plot the learning curves
plt.figure(figsize=(12, 8))
for metric in ['rmse', 'mae', 'r2', 'ev', 'msle', 'medianae']:
    plt.plot(range(1, epochs + 1), avg_learning_curves[metric], label=f'Test {metric.upper()}')
    plt.plot(range(1, epochs + 1), avg_learning_curves[f'{metric}_train'], linestyle='dashed', label=f'Train {metric.upper()}')
    plt.xlabel("Epochs")
    plt.ylabel(metric.upper())
    plt.title(f"Learning Curve for {metric.upper()}")
    plt.legend()
    plt.grid(True)
    plt.show()

# Print unscaled average metrics
print("\nUnscaled Average metrics across all folds:")
print(f"Average RMSE: {np.mean(rmse_scores)}")
print(f"Average MAE: {np.mean(mae_scores)}")
print(f"Average R2: {np.mean(r2_scores)}")
print(f"Average Explained Variance (EV): {np.mean(ev_scores)}")
print(f"Average MSLE: {np.mean(msle_scores)}")
print(f"Average MedianAE: {np.mean(medianae_scores)}")
